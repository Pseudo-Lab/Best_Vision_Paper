<h1 align="center"> Best Vision Paper </h1>

<div align="center">
<a href="https://discord.gg/EPurkHVtp2"><img src="https://img.shields.io/badge/Discord-BF40BF" alt="Discord Community"/></a>
<a href="https://github.com/Pseudo-Lab/Best_Vision_Paper/stargazers"><img src="https://img.shields.io/github/stars/Pseudo-Lab/Best_Vision_Paper" alt="Stars Badge"/></a>
<a href="https://github.com/Pseudo-Lab/Best_Vision_Paper/network/members"><img src="https://img.shields.io/github/forks/Pseudo-Lab/Best_Vision_Paper" alt="Forks Badge"/></a>
<a href="https://github.com/Pseudo-Lab/Best_Vision_Paper/pulls"><img src="https://img.shields.io/github/issues-pr/Pseudo-Lab/Best_Vision_Paper" alt="Pull Requests Badge"/></a>
<a href="https://github.com/Pseudo-Lab/Best_Vision_Paper/issues"><img src="https://img.shields.io/github/issues/Pseudo-Lab/Best_Vision_Paper" alt="Issues Badge"/></a>
<a href="https://github.com/Pseudo-Lab/Best_Vision_Paper/graphs/contributors"><img alt="GitHub contributors" src="https://img.shields.io/github/contributors/Pseudo-Lab/Best_Vision_Paper?color=2b9348"></a>
<a href="https://hits.seeyoufarm.com"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2FPseudo-Lab%2FBest_Vision_Paper&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false"/></a>
</div>
<br>

<!-- sheilds: https://shields.io/ -->
<!-- hits badge: https://hits.seeyoufarm.com/ -->

> Welcome to the Best Vision Paper Team Repository.
>
> We review and analyze the best papers from top-tier vision conferences including CVPR, ICCV, ECCV, and NeurIPS and more.
>
> Our team dives deep into these groundbreaking papers to understand their novel approaches and technical innovations.
> These award-winning papers represent the pinnacle of computer vision research, offering crucial insights into where the field is heading.
> Through careful analysis and discussion, we aim to understand not just the technical details, but also the key insights that drive the field forward.
> 
> What we do:
> - **Comprehensive Reviews** for in-depth best vision paper analysis
> - Weekly discussions to **share insights** and **explore potential research directions**
> - Technical deep-dives including code analysis and implementation details when available
>   
> Join us in advancing the field of computer vision through open collaboration and innovation!

<br>

> ì €í¬ íŒ€ì€ ìŠ¤í„°ë””ë¥¼ í†µí•´ ìµœê³  ìˆ˜ì¤€ì˜ ë¹„ì „ ì»¨í¼ëŸ°ìŠ¤ì—ì„œ ìˆ˜ìƒí•œ ë…¼ë¬¸ë“¤ì„ ì‹¬ì¸µ ë¶„ì„í•˜ê³ , ë„ì¶œí•œ ì•„ì´ë””ì–´ì™€ ì¸ì‚¬ì´íŠ¸ë¥¼ ê³µìœ í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.
> 
> ìˆ˜ìƒ ê²½ë ¥ì— ë¹›ë‚˜ëŠ” ë…¼ë¬¸ë“¤ì€ ì»´í“¨í„° ë¹„ì „ ì—°êµ¬ì˜ ì •ì ì„ ë‚˜íƒ€ë‚´ë©°, ë¹„ì „ ë¶„ì•¼ê°€ ë‚˜ì•„ê°ˆ ë°©í–¥ì— ëŒ€í•œ ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
> 
> ë”°ë¼ì„œ ì‹¬ì¸µì  í† ë¡ ì„ í†µí•´ ë¹„ì „ ì—°êµ¬ì˜ ë¯¸ë˜ë¥¼ íƒìƒ‰ ë° ëŒ€ì‘í•˜ê³  ì—°êµ¬ ì—­ëŸ‰ ê°•í™”ë¥¼ í†µí•œ ì„±ì¥ì„ ì¶”êµ¬í•˜ëŠ” ë¶„ì„ ëª¨ì‹œê³ ì í•©ë‹ˆë‹¤.
> 
> ë…¼ë¬¸ì€ 2ë…„ ì´ë‚´(2023~)ì˜ ìµœê³  ë¹„ì „ ì»¨í¼ëŸ°ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ììœ¨ì ìœ¼ë¡œ ì„ ì • ë° ë°œí‘œë¥¼ ì§„í–‰í•  ì˜ˆì •ì…ë‹ˆë‹¤.(ë‚˜ë¨¸ì§€ Github ì°¸ì¡°)

<br>

## ğŸŒŸ í”„ë¡œì íŠ¸ ëª©í‘œ (Project Vision)
_"ë‹¤ì–‘í•œ ë¹„ì „(Vision) ë…¼ë¬¸ì„ ì‹¬ì¸µ ë¶„ì„í•˜ê³ , ê³µìœ ì™€ í˜‘ì—…ì„ í†µí•´ ìƒˆë¡œìš´ í†µì°°ì„ ì–»ê¸°"_  
- **ìµœì‹  ë¹„ì „ ì—°êµ¬ ë™í–¥ íƒìƒ‰**ì„ í†µí•´ **ë¹ ë¥´ê²Œ ë³€í™”í•˜ëŠ” ë¹„ì „ ë¶„ì•¼ì˜ í•µì‹¬ íŠ¸ë Œë“œ**ì— ëŒ€ì‘
- **ì‹¬ì¸µì  ë…¼ë¬¸ ë¶„ì„** ë° **ì¸ì‚¬ì´íŠ¸ ë„ì¶œ**ì„ í†µí•œ ì—°êµ¬ ì—­ëŸ‰ ê°•í™”
- **í˜‘ì—… ê¸°ë°˜ì˜ ì§€ì‹ ê³µìœ **ë¥¼ í†µí•œ ì˜¤í”ˆì†ŒìŠ¤ ì •ì‹  ì§€í–¥
- **ê°œì¸ ì—­ëŸ‰ ê°•í™”** ë° **ë„¤íŠ¸ì›Œí‚¹ í™•ì¥**ì„ í†µí•œ ë¯¸ë˜ ê¸°íšŒ ëª¨ìƒ‰í•˜ê¸°

<br>

## ë…¼ë¬¸ ì„ ì • 
- 2ë…„ ì´ë‚´ Top-Tier Vision Conferenceì—ì„œ ì„ ì •ëœ Best (Student) paper, Spotlight í˜¹ì€ ì´ì— ì¤€í•˜ëŠ” ë…¼ë¬¸
  - ëŒ€ìƒ í•™íšŒ: CVPR, ICCV, ICLR, ICML, ECCV, NeurIPS, AAAI ë“± Top-tier Vision í•™íšŒ
  - ì°¸ê³  ìë£Œ
      - [Best Papers Top Venues](https://github.com/SarahRastegar/Best-Papers-Top-Venues)
      - [CVPR 2024 Best Paper Award Winners](https://www.computer.org/press-room/cvpr-2024-announces-best-paper-award-winners)
    
- ì‹œì˜ì„±ì´ í° Tech Report 
  - ì˜ˆì‹œ: 2025 CES NVIDIA Cosmos, BigTech Tech Report

ê°œì¸ì˜ ì„ í˜¸ì— ë§ê²Œ ììœ¨ì ìœ¼ë¡œ ì„ íƒ ë° ë°œí‘œ ì§„í–‰

<br>

## ë°œí‘œì ì§„í–‰ ì•ˆë‚´
- ë…¼ë¬¸ ê³ ì§€ : ë°œí‘œì¼ë¡œë¶€í„° **ìµœì†Œ 2ì£¼ ì „** ë°œí‘œí•  ë…¼ë¬¸ì„ ë‚´ë¶€ **Discordì— ì‚¬ì „ ê³ ì§€** & **Github ì£¼ì°¨ë³„ í™œë™ì— ê¸°ì…**
- ë°œí‘œ ìë£Œ : ììœ¨ì ìœ¼ë¡œ êµ¬ì„± ë° ì‘ì„±
- ë°œí‘œ í›„ : githubì— ìë£Œ ê³µìœ 
<br>

## íŒŒì¼ ê³µìœ  ë°©ë²•

- ë°©ë²• 1. ì§„í–‰í•œ ë°œí‘œìë£Œë¥¼ 1) "Github Repository ë‚´ upload" í˜¹ì€ 2) "í´ë¼ìš°ë“œ ë‚´ upload" ì§„í–‰. (ê°€ê¸‰ì  Repository upload ìš”ì²­)
  - "Github Repository ë‚´ upload" ì§„í–‰ì‹œ : Conferenceë³„ ì—°ë„ë³„ íŒŒì¼ upload ì§„í–‰ ìš”ì²­.
  - "í´ë¼ìš°ë“œ ë‚´ upload" ì§„í–‰ì‹œ : ì „ì²´ ê³µìœ ê°€ ê°€ëŠ¥í•œ ë§í¬ ì¤€ë¹„ ìš”ì²­.
- ë°©ë²• 2. uploadí•œ ë°œí‘œìë£Œ ë§í¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ presentations í´ë” ë‚´ì— ì¡´ì¬í•˜ëŠ” [conference_upload_list.md](https://github.com/Pseudo-Lab/Best_Vision_Paper/blob/main/presentations/conference_upload_list.md) íŒŒì¼ì— ê¸°ì….

e.g. 
CVPRì˜ ê²½ìš° í•´ë‹¹ ëª©ì°¨ ìƒì„± í›„ ì•„ë˜ì™€ ê°™ì€ Table êµ¬ì„± ì§„í–‰í•¨.

| Paper Title | Award | Project Page / Arxiv Page | Presenter | URL | 
| --------| -------- | -------- | -------- | -------- |
| 2024 |||||
| Generative Image Dynamics | CVPR 2024, Best Paper Award | [Project](https://generative-dynamics.github.io/) / [Arxiv](https://arxiv.org/abs/2309.07906) | Geonhak Song | [presenter_file](https://github.com/Pseudo-Lab/Best_Vision_Paper/blob/main/presentations/CVPR/2024/%5BCVPR%202024%5D%20Generative%20Image%20Dynamics%20(Best%20Paper%20Award).pdf) |

<br>

## ğŸŒ± ì°¸ì—¬ ì•ˆë‚´ (How to Engage)

**ëˆ„êµ¬ë‚˜ ì²­ê°•ì„ í†µí•´ ëª¨ì„ì„ ì°¸ì—¬í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.**  
- íŠ¹ë³„í•œ ì‹ ì²­ ì—†ì´ ë§¤ì£¼ í™”ìš”ì¼ ì˜¤í›„ 9:00~10:30ì— ë§ì¶”ì–´ ë””ìŠ¤ì½”ë“œ #Room-AT ì±„ë„ë¡œ ì…ì¥
- 1ê¸° : 2025.03.04 ~ 2025.06.24

<br>

## ğŸ§‘ Contributor 

| ì—­í•           | ì´ë¦„ |  ê´€ì‹¬ ë¶„ì•¼                                                               | LinkedIn                         |
|---------------|------|-----------------------------------------------------------------------|----------------------------------------|
| **Project Manager** | ì†¡ê±´í•™ | Vision ê¸°ë°˜ Generative AI (2D, 3D etc), Agent | [LinkedIN](https://www.linkedin.com/in/geonhak-song-09a037165/) |
| **Member** | ê³ ì¬í›ˆ | Multi-modal Learning, 3D Vision | [LinkedIN](https://www.linkedin.com/in/jaehoon2123/) |
| **Member** | ê³µì„±íƒ |  |                |
| **Member** | ê¹€ëª…ì„­ | Medical AI, Generative AI (2D, 3D etc) | [LinkedIN](https://www.linkedin.com/in/kmscopra/) |
| **Member** | ê¹€ì§€í™˜ | Generative Model, Segmentation (3D Medical image) | [LinkedIN](https://www.linkedin.com/in/kuchoco97/) |
| **Member** | ì±„ì§„ì˜ | Multi-modal learning, Knowledge-based reasoning, Agent | [LinkedIN](https://www.linkedin.com/in/jinyeong-chae419) |

<br>

## ğŸš€ Best Vision Paper Team ë¡œë“œë§µ (Roadmap)
```mermaid
gantt
    title 2025 Best Vision Paper Team ì—¬ì •
    section ì¼ì •    
    OT & cycle       :a1, 2025-03-04, 96d    
    section ê°€ì§œì—°êµ¬ì†Œ í™œë™
    Magical Week1: 2025-03-23, 7d
    Magical Week2: 2025-04-27, 7d
    íœ´ì¼ì£¼ì°¨ (05.06): holiday, 2025-05-04, 7d
    PseudoCon 2025     : conference, 2025-05-17, 1d
    
```

<br>

## ğŸ’» ì£¼ì°¨ë³„ í™œë™ (Activity History)

|íšŒì°¨| ë‚ ì§œ | ë…¼ë¬¸ ì´ë¦„ | í•™íšŒ : ìˆ˜ìƒ ì´ë ¥ | Project/ë…¼ë¬¸ ë§í¬ | ë°œí‘œì | 
| --------| -------- | -------- | -------- | -------- | ---- |
|1| 2025/03/04 | OT ||| ì†¡ê±´í•™ | 
|2| 2025/03/11 | Generative Image Dynamics | CVPR 2024, Best Paper Award | [Project](https://generative-dynamics.github.io/) / [Arxiv](https://arxiv.org/abs/2309.07906) | ì†¡ê±´í•™ | 
|3| 2025/03/18 | Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video | ICLR 2024, Honorable Mention |[Project](https://shashankvkt.github.io/dora) / [Arxiv](https://arxiv.org/abs/2309.07906) | ê³ ì¬í›ˆ | 
|4| 2025/03/25 | Magical Week ||| | 
|5| 2025/04/01 | PixelSplat: 3D Gaussian Splats from Image Pairs for Scalable Generalizable 3D Reconstruction | CVPR 2024, Honorable Mention |[Project](https://davidcharatan.com/pixelsplat/) / [Arxiv](https://arxiv.org/abs/2312.12337)| ê³µì„±íƒ | 
|6| 2025/04/08 | Protein Discovery with Discrete Walk-Jump Sampling | ICLR 2024, Outstanding Papers | [Arxiv](https://arxiv.org/abs/2306.12360) | ê¹€ì§€í™˜ | 
|7| 2025/04/15 | Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction | NeurIPS 2024, Best Paper |[Project](https://github.com/FoundationVision/VAR) / [Arxiv](https://arxiv.org/pdf/2404.02905) | ì±„ì§„ì˜ | 
|8| 2025/04/22 | Rich Human Feedback for Text-to-Image Generation | CVPR 2024, Best Paper Award | [Project](https://github.com/google-research/google-research/tree/master/richhf_18k) / [Arxiv](https://arxiv.org/abs/2312.10240) | ê¹€ëª…ì„­ | 
|9| 2025/04/29 | Magical Week |||  | 
|10| 2025/05/06 | ëŒ€ì²´ íœ´ì¼ ||| | 
|11| 2025/05/13 | Reliable Conflictive Multi-view Learning | AAAI 2024, Outstanding Paper Award | [Project](https://github.com/jiajunsi/RCML) / [Arxiv](https://arxiv.org/abs/2402.16897) | ê³ ì¬í›ˆ | 
|12| 2025/05/20 | TBD ||| TBD (1ëª…) | 
|13| 2025/05/27 | TBD ||| ê¹€ì§€í™˜ | 
|14| 2025/06/03 | ëŒ€ì„  íœ´ì¼ ||| | 
|15| 2025/06/10 | TBD ||| ì†¡ê±´í•™ | 
|16| 2025/06/17 | TBD ||| TBD (1ëª…) | 
|17| 2025/06/24 | TBD ||| TBD (1ëª…) | 
|18| 2025/07/01 | TBD ||| TBD (1ëª…) | 


<br>

## Acknowledgement ğŸ™

Best Vision Paper Team is developed as part of Pseudo-Lab's Open Research Initiative. Special thanks to our contributors and the open source community for their valuable insights and contributions.

## About Pseudo Lab ğŸ‘‹ğŸ¼</h2>

[Pseudo-Lab](https://pseudo-lab.com/) is a non-profit organization focused on advancing machine learning and AI technologies. Our core values of Sharing, Motivation, and Collaborative Joy drive us to create impactful open-source projects. With over 5k+ researchers, we are committed to advancing machine learning and AI technologies.

<h2>Contributors ğŸ˜ƒ</h2>
<a href="https://github.com/Pseudo-Lab/Best_Vision_Paper/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=Pseudo-Lab/Best_Vision_Paper" />
</a>
<br><br>

<h2>License ğŸ—</h2>

This project is licensed under the [MIT License](https://opensource.org/licenses/MIT).
